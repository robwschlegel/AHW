---
title: "Cluster Results"
# author: "Robert Schlegel"
# date: "30 March 2017"
output: pdf_document
bibliography: AHW.bib
csl: elsevier-harvard.csl
---

# Concepts that need to be investigated
Much has been done thus far in regards to the research, and a clear picture of what is further required now exists. The work with SOMs is likely sound, but does require that a few more variables be tested. Furthermore, it is not yet certain that SOMs will be the best clustering technique. To that end, K-means clustering and hierarchical clustering have also been identified as alternative techniques. This now gives rise to the possibility that two papers could emerge from this work. One on the resultant clustering of synoptic air-sea states during coastal MHWs, and another paper that discusses the strengths of these various clustering techniques.

## The metrics for each MHW in each cluster
This requires that once the different events have been clustered, regardless of the technique used, or the variables controlled for within (see below), a summary of the event metrics must also be provided. These then will allow for the second more meaningful round of the interpretation of the results.

![The results of a SOM clustering of the syoptic air-sea anaomaly data during coastal MHWs. The clusters shown here correspond to the following table and figure.](~/AHW/graph/som/anom_9.pdf)

```{r, warning=FALSE, message=FALSE, echo=FALSE, results='asis'}
# Load SOM results from anomaly data prepared by "proc/results.som.R"
load("results/node_all_anom_pci_1r.Rdata")
# Run the metric summary function on these data
source("~/AHW/func/som.func.R")
node_all_anom_table <- node.summary.metrics(node_all_anom_pci_1r)
## This produces text that LaTeX likes
# library(xtable)
# xtable(node_all_anom_table, caption = "The possible metrics that may be of interest for summarising the events clustered into each node.")
## This produces a better default for RMarkdown, but doesn't produce acceptable legends without a bit of faffing about
## See: http://stackoverflow.com/questions/19997242/simple-manual-rmarkdown-tables-that-look-good-in-html-pdf-and-docx
library(pander)
pander(node_all_anom_table, caption = "The possible metrics that may be of interest for summarising the events clustered into each node. Node numbers given here correspond to Figure 1 and 2.")
```
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Lolliplots showing start date and cummulative intensity of each event by each node, as seen in Figure 1."}
# Visualise the start dates and int_cum of the events via lolliplots
library(RmarineHeatWaves)
library(ggplot2)
node_all_anom_2 <- merge(node_all_anom_pci_1r, event_list, by = c("event", "site", "season", "event_no"))
ggplot(data = node_all_anom_2, aes(x = date_start, y = int_cum)) +
  geom_lolli() +
  facet_wrap(~node) +
  labs(x = "date", y = "cummulative intensity (Cxdays)")
```

Figure 2 most clearly demonstrates that the SOM nodes in Figure 1 generally consist of either several events that occurred at the same time, or a blend of many disparate events. The nodes that contain more events are therefore much more 'neutral', meaning there is very little visible by way of air-sea anomalies. This is as I had feared and is currently my largest criticism of this technique. If one were to add more SOM nodes (a bad idea given that there are only 95 data vectors to be clustered), the new nodes will only allow some of the events within the larger clusters to break away and form their own node. The complexity of the air-sea states is such that any consistent patterns that may occur are obfuscated by everything else happening in the study area. Therefore it is necessary to reduce the dimensions of the input data by drawing a more narrow box around the study area to investigate the effect this may have. But first, the BRAN data need to be appropriately rounded down to a resolution of 0.5 degrees in order to match the ERA-Interim data.


## Comparing large replication sets
Because the SOM nodes are shuffled during each run, comparing the results directly becomes difficult. We can however iterate the SOM analysis many times and save a vector of results for each event showing into which node it was cast for each run. This then creates a unique information vector for each event that can then be used to further cluster the events into 'mean' clusters. This helps to address the issue of SOM node 'drift'. The following two tables show the results of a SOM run on the data 10 times.
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# Load 0.5 res data
load("results/all_anom_0.5.Rdata")
load("results/node_all_anom_1r.Rdata")

## Run the analysis once
# system.time(som_all_anom_1r <- som.model(all_anom_0.5)) # 4 seconds
# node_all_anom_1r <- event.node(all_anom_0.5, som_all_anom_1r, kohonen = TRUE)
# save(node_all_anom_1r, file = "results/node_all_anom_1r.Rdata")
# load("results/node_all_anom_1r.Rdata")
# node_all_anom_1r <- node_all_anom_1r[,1:3]
# colnames(node_all_anom_1r) <- c("event", "node_1", "count_1")

## Run the analysis 10 times
# node_all_anom_10r <- node_all_anom_1r
# for(i in 2:10){
#   som_all_anom_10r <- som.model(all_anom_0.5)
#   df <- event.node(all_anom_0.5, som_all_anom_10r, kohonen = TRUE)
#   node_all_anom_10r <- cbind(node_all_anom_10r, df[,2:3])
# }
# save(node_all_anom_10r, file = "results/node_all_anom_10r.Rdata")
load("results/node_all_anom_10r.Rdata")

# node_res <- node_all_anom
node.count.n <- function(node_res, resolution){
  df_1 <- unique(node_res[,2:3])
  df_1 <- df_1[order(df_1$node),]
  rownames(df_1) <- df_1$node
  df_1 <- data.frame(df_1[,2])
  colnames(df_1) <- resolution
  return(df_1)
}

node_diff_10 <- node.count.n(node_all_anom_10r, "1r")
for(i in 2:10){
  j <- i*2
  res <- node.count.n(node_all_anom_10r[,c(1,j,j+1)], paste0(i,"r"))
  node_diff_10 <- cbind(node_diff_10, res)
}
pander(node_diff_10, caption = "Table showing the number of events within the same node over 10 runs on the same data. Note how variable the node assignments may be.")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# Order the 10 SOM run in descending order
node_diff_10_2 <- apply(node_diff_10, 2, sort)
pander(node_diff_10_2, caption = "Table showing the number of events within a node scored in descending order. The different columns show each run. Note that the results are generally consistent, but not completely.")
```

Now let's up the anti a bit and run the SOM 100 times. Because the resultant data frame will become unwieldy, we will create means across the number of clustered events as coerced into descending order. These then will be compared to the mean for the 1 run and 10 run data frames.
```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Run the analysis 100 times
# node_all_anom_100r <- node_all_anom_10r
# for(i in 11:100){
#   som_all_anom_100r <- som.model(all_anom_0.5)
#   df <- event.node(all_anom_0.5, som_all_anom_100r, kohonen = TRUE)
#   node_all_anom_100r <- cbind(node_all_anom_100r, df[,2:3])
# }
# save(node_all_anom_100r, file = "results/node_all_anom_100r.Rdata")
load("results/node_all_anom_100r.Rdata")

# Compute counts per node
node_diff_100 <- node.count.n(node_all_anom_1r, "1r")
for(i in 2:100){
  j <- i*2
  res <- node.count.n(node_all_anom_100r[,c(1,j,j+1)], paste0(i,"r"))
  node_diff_100 <- cbind(node_diff_100, res)
}

# Order
node_diff_100_2 <- apply(node_diff_100, 2, sort)

# Create means from each dataframe
node_diff_1_mean <- data.frame(node_diff_100_2[,1])
colnames(node_diff_1_mean) <- "1r"
node_diff_10_mean <- data.frame(round(apply(node_diff_100_2[,1:10], 1, mean),0))
colnames(node_diff_10_mean) <- "10r"
node_diff_100_mean <- data.frame(round(apply(node_diff_100_2, 1, mean),0))
colnames(node_diff_100_mean) <- "100r"
node_diff_mean <- cbind(node_diff_1_mean, node_diff_10_mean, node_diff_100_mean)

# Table
pander(node_diff_mean, caption = "Table showing the number of events within a node scored in descending order. The different columns show the mean of 1, 10, and 100 SOM runs. Note that the results are remarkably similar.")
```

As we may see from the table above, the 'wobble' present in the SOM analysis is not great. I considered running the analysis 1,000 times but this would take several hours on my computer and I think that the consistency shown between 1, 10, and 100 runs is sufficient to put this question to rest.


## RI vs PCI
Even though the 'wobble' in the SOM algorithm has been shown to be small, it would be better if it was non-existent. This would allow for better comparison of the variables below as well as complete reproducibility by anyone interested in doing the work themselves. Previously with this work SOMs were being run with random initialisation (RI). In order to ensure consistent results it is necessary to use principal component initialisation (PCI). The `kohonnen` package that has been used thus far for SOMs does not have this capability so it is necessary to use a different package, `SOMbrero`. This package however uses `princomp` when calculating PCI, which doesn't work when one has more columns than rows. So yet another self-organising map implementation `yasomi` must be used as this allows one to chose `prcomp` for PCI, which works with our wide dataframe.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Run the analysis with PCI once
# system.time(som_mdel_pci <- som.model.PCI(all_anom_0.5)) # 5 seconds
# node_all_anom_pci_1r <- event.node(all_anom_0.5, som_mdel_pci, kohonen = FALSE)
# save(node_all_anom_pci_1r, file = "results/node_all_anom_pci_1r.Rdata")
load("results/node_all_anom_pci_1r.Rdata") # This is the correct SOM node file to use for all future analyses #
# node_all_anom_pci_1r <- node_all_anom_pci_1r[,1:3]
# colnames(node_all_anom_1r) <- c("event", "node_1", "count_1")

## Run the analysis 10 times
# node_all_anom_pci_10r <- node_all_anom_pci_1r
# for(i in 2:10){
#   som_all_anom_pci_10r <- som.model.PCI(all_anom_0.5)
#   df <- event.node(all_anom_0.5, som_all_anom_pci_10r, kohonen = FALSE)
#   node_all_anom_pci_10r <- cbind(node_all_anom_pci_10r, df[,2:3])
# }
# save(node_all_anom_pci_10r, file = "results/node_all_anom_pci_10r.Rdata")
load("results/node_all_anom_pci_10r.Rdata")

node_diff_pci_10 <- node.count.n(node_all_anom_pci_10r, "1r")
for(i in 2:10){
  j <- i*2
  res <- node.count.n(node_all_anom_pci_10r[,c(1,j,j+1)], paste0(i,"r"))
  node_diff_pci_10 <- cbind(node_diff_pci_10, res)
}
pander(node_diff_pci_10, caption = "Table showing the number of events within the same node over 10 runs on the same data using PCI. Note how events are always placed in the same nodes.")
```

As we may see in the table above, using principal component initialisation, instead of random initialisation prevents any of the 'wobble' of events between nodes. For this reason it is preferable to use PCI instead of RI moving forward. Because all SOMs will now be initialised with PCI, it will not be included in the file names. Rather it will be assumed to be the standard.


## Effect of pixel resolution on clustering
The more dimensions/ variables one introduces to a cluster analysis, the more stress will exist in the results. As large stress values are generally considered to be a negative result in clustering, it is best to attempt to reduce it where possible. One way of doing that for this research is by reducing the pixel resolution of the reanalysis products. There are two reasons that this cannot simply be done out of hand. The first is that the reduction in resolution may affect the clustering of the events. So this must be documented. The other problem this presents is that the reduction of pixel resolution would require that any results produced be shown at this same reduced resolution. And because the goal is to show meso-scale forcing on the coast, higher pixel resolutions would be preferable. Regardless, the ERA-Interim data are at a resolution of 0.5 degrees, which requires that the BRAN data be reduced to this same resolution for appropriate cluster comparison. Beyond this initial required reduction in resolution, the question then is what effect does the further rounding of the data produce? Here we look at three resolutions: 0.5, 1.0 and 2.0 degree lon/ lat.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Here the data are transformed and saved and re-loaded for convenience
# "all_anom.Rdata" was prepared by "proc/results.som.R"
# load("results/all_anom.Rdata")
# system.time(all_anom_0.5 <- synoptic.round(all_anom, 0.5)) # 115 seconds
# save(all_anom_0.5, file = "results/all_anom_0.5.Rdata")
# load("results/all_anom_0.5.Rdata")
# system.time(all_anom_1.0 <- synoptic.round(all_anom, 1.0)) # 134 seconds
# save(all_anom_1.0, file = "results/all_anom_1.0.Rdata")
# load("results/all_anom_1.0.Rdata")
# system.time(all_anom_2.0 <- synoptic.round(all_anom, 2.0)) # 126 seconds
# save(all_anom_2.0, file = "results/all_anom_2.0.Rdata")
# load("results/all_anom_2.0.Rdata")

## After loading the clustering of events is counted and saved
# system.time(node_all_anom <- node.count(all_anom, "res_all")) # 66 seconds
# save(node_all_anom, file = "results/node_all_anom.Rdata")
# system.time(node_all_anom_0.5 <- node.count(all_anom_0.5, "res_0.5")) # 5 seconds
# save(node_all_anom_0.5, file = "results/node_all_anom_0.5.Rdata")
# system.time(node_all_anom_1.0 <- node.count(all_anom_1.0, "res_1.0")) # 1 seconds
# save(node_all_anom_1.0, file = "results/node_all_anom_1.0.Rdata")
# system.time(node_all_anom_2.0 <- node.count(all_anom_2.0, "res_2.0")) # 1 seconds
# save(node_all_anom_2.0, file = "results/node_all_anom_2.0.Rdata")

## Load node counts to appraise differences
load("results/node_all_anom.Rdata")
load("results/node_all_anom_0.5.Rdata")
load("results/node_all_anom_1.0.Rdata")
load("results/node_all_anom_2.0.Rdata")

node_diff <- cbind(node_all_anom, node_all_anom_0.5, node_all_anom_1.0, node_all_anom_2.0)
pander(node_diff, caption = "Table showing the number of events clustered into which of the 9 SOM nodes. The different columns show the effect that reducing the resolution of the data has on the clustering.")
```

The results table generated from the clustering of events into different nodes shown above shows that when the resolution of the BRAN data are not rounded down to that of the ERA-Interim data they have a pronounced effect on the clustering of the events. Specifically more events are lumped together in node 1, the "other" node. By reducing the resolution of BRAN to match ERA, the clustering of events becomes more even across the nodes. As we reduce the resolution further there is some shifting of a few events but the overall pattern remains. It is also helpful to see the nodes in descending order of the number of events in each nodes as seen below.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
node_diff_2 <- apply(node_diff, 2, sort)
pander(node_diff_2, caption = "Table showing the number of events within a node scored in descending order. The different columns show the effect that reducing the resolution of the data has on the clustering.")
```

When the data are reshuffled into descending order based on the number of events clustered into each node we see that the results are very similar for resolutions coarser than 0.5. This shows us that it is not necessary to consider the use of coarser resolutions as 0.5 is most appropriate.


## Effect of lat/ lon extent on clustering
With more traditional cluster analyses, the values being compared would have far fewer dimensions. In this regard one would endeavour to only include variables that seem relevant to the question being asked. For example, if clustering different rock pools by the species found within them, one would likely create better results by not including any anomalous species found in the results (like a cow fish). In regards to this work, it is best to include only the pixels that are likely relevant to the meso-scale features that may be impacting the coast. More specifically, cutting out the Agulhas retroflection above the Southern Ocean will prevent any behaviour there from affecting the clustering of events that are occurring along the coastline of South Africa.

That all being said, it may indeed be relevant, at least in the sense of potential teleconnections, to include the Agulhas retroflections over the Southern Ocean. I have decided to trim the total study area by 1 degree on the East, South and West extents, rather than just the South extent. The northern border of the study area is left unchanged as this would begin to remove some of the coastal stations. The effect of trimming the study area 1 degree at a time is presented below. A SOM is run on each trimmed dataframe. A total of 5 degrees are iteratively trimmed.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Trim the data
# all_anom_0.5_trim_1 <- synoptic.trim(all_anom_0.5, 1)
# save(all_anom_0.5_trim_1, file = "results/all_anom_0.5_trim_1.Rdata")
load("results/all_anom_0.5_trim_1.Rdata")
# all_anom_0.5_trim_2 <- synoptic.trim(all_anom_0.5, 2)
# save(all_anom_0.5_trim_2, file = "results/all_anom_0.5_trim_2.Rdata")
load("results/all_anom_0.5_trim_2.Rdata")
# all_anom_0.5_trim_3 <- synoptic.trim(all_anom_0.5, 3)
# save(all_anom_0.5_trim_3, file = "results/all_anom_0.5_trim_3.Rdata")
load("results/all_anom_0.5_trim_3.Rdata")
# all_anom_0.5_trim_4 <- synoptic.trim(all_anom_0.5, 4)
# save(all_anom_0.5_trim_4, file = "results/all_anom_0.5_trim_4.Rdata")
load("results/all_anom_0.5_trim_4.Rdata")
# all_anom_0.5_trim_5 <- synoptic.trim(all_anom_0.5, 5)
# save(all_anom_0.5_trim_5, file = "results/all_anom_0.5_trim_5.Rdata")
load("results/all_anom_0.5_trim_5.Rdata")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# Compute the SOM results for the different trims
# trim_0_nodes <- data.frame(node_diff[,2])
# colnames(trim_0_nodes) <- "trim_0"
# trim_1_nodes <- node.count(all_anom_0.5_trim_1, "trim_1")
# trim_2_nodes <- node.count(all_anom_0.5_trim_2, "trim_2")
# trim_3_nodes <- node.count(all_anom_0.5_trim_3, "trim_3")
# trim_4_nodes <- node.count(all_anom_0.5_trim_4, "trim_4")
# trim_5_nodes <- node.count(all_anom_0.5_trim_5, "trim_5")

# Combine and save
# trim_all_nodes <- cbind(trim_0_nodes, trim_1_nodes, trim_2_nodes,
#                         trim_3_nodes, trim_4_nodes, trim_5_nodes)
# trim_all_nodes <- apply(trim_all_nodes, 2, sort)
# save(trim_all_nodes, file = "results/trim_all_nodes.Rdata")
load("results/trim_all_nodes.Rdata")
# Table
pander(trim_all_nodes, caption = "Table showing the number of events within each node scored in descending order. The different columns show the differing amounts of spatial reduction in the extent of the study area. Note that the results remain similar when 1 to 4 degrees of pixels are trimmed, but there appears to be a difference in the results when the full study range is used and when 5 degrees of lon & lat have been removed from the East, South, and West edges of the study area.")
```

The table above shows that removing the first degree of lon/ lat around the study area does have an effect on the SOM clustering. Leaving the study area 'as is' is shown in the column labeled 'trim_0'. These are the results shown in the previous tables and figures. Removing 1 to 4 degrees of lat/ lon has all have similar effects and appear to spread the clustering of the events a bit more than using the full study area. Trimming  5 degrees of lat/ lon smooths the clustering noticeably more. The difference between these different extents is not large, but I think it does show that the edges of the study area are having an effect on the clustering. And that reducing the area does allow for a more even clustering of the events into nodes. It may be best to use a study area with 1 degrees trimmed from the East, South, and West edges. But for now I shall continue to use the full study area.


## Effect of running air and sea variables separately
It may be that air and sea values work in tandem with one another to force MHWs, but it is more likely that they do not. Except for perhaps VERY extreme situations (e.g. once per decade). Therefore it is necessary to run all clustering techniques on air-sea values combined, as well as separately, in order to quantify the potential effect they have on clustering. Up until this point all variables have been run together, here we pull them apart to see how the results may differ. We do this by running all air or sea variables together and then by running air or sea temperature and wind/ current vectors separately.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
# split air and sea
# all_anom_0.5_sea <- synoptic.sub(all_anom_0.5, "BRAN")
# save(all_anom_0.5_sea, file = "results/all_anom_0.5_sea.Rdata")
load("results/all_anom_0.5_sea.Rdata")
# all_anom_0.5_air <- synoptic.sub(all_anom_0.5, "ERA")
# save(all_anom_0.5_air, file = "results/all_anom_0.5_air.Rdata")
load("results/all_anom_0.5_air.Rdata")

### Split temperature from current vectors
## Sea
# all_anom_0.5_sea_temp <- synoptic.sub(all_anom_0.5_sea, "temp")
# save(all_anom_0.5_sea_temp, file = "results/all_anom_0.5_sea_temp.Rdata")
load("results/all_anom_0.5_sea_temp.Rdata")
# all_anom_0.5_sea_u <- synoptic.sub(all_anom_0.5_sea, "u")
# all_anom_0.5_sea_v <- synoptic.sub(all_anom_0.5_sea, "v")
# all_anom_0.5_sea_uv <- cbind(all_anom_0.5_sea_u, all_anom_0.5_sea_v[,-1])
# save(all_anom_0.5_sea_uv, file = "results/all_anom_0.5_sea_uv.Rdata")
load("results/all_anom_0.5_sea_uv.Rdata")
## Air
# all_anom_0.5_air_temp <- synoptic.sub(all_anom_0.5_air, "temp")
# save(all_anom_0.5_air_temp, file = "results/all_anom_0.5_air_temp.Rdata")
load("results/all_anom_0.5_air_temp.Rdata")
# all_anom_0.5_air_u <- synoptic.sub(all_anom_0.5_air, "u")
# all_anom_0.5_air_v <- synoptic.sub(all_anom_0.5_air, "v")
# all_anom_0.5_air_uv <- cbind(all_anom_0.5_air_u, all_anom_0.5_air_v[,-1])
# save(all_anom_0.5_air_uv, file = "results/all_anom_0.5_air_uv.Rdata")
load("results/all_anom_0.5_air_uv.Rdata")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Run 10 SOMs based on the split air or sea data and sum the results
# Sea
# sea_all_nodes <- node.count(all_anom_0.5_sea, "sea_all")
# sea_temp_nodes <- node.count(all_anom_0.5_sea_temp, "sea_temp")
# sea_uv_nodes <- node.count(all_anom_0.5_sea_uv, "sea_uv")
# Air
# air_all_nodes <- node.count(all_anom_0.5_air, "air_all")
# air_temp_nodes <- node.count(all_anom_0.5_air_temp, "air_temp")
# air_uv_nodes <- node.count(all_anom_0.5_air_uv, "air_uv")

# Combine and save
# sub_all_nodes <- cbind(trim_all_nodes[,1], air_all_nodes, air_temp_nodes, air_uv_nodes, 
#                        sea_all_nodes, sea_temp_nodes, sea_uv_nodes)
# colnames(sub_all_nodes)[1] <- "all_all"
# sub_all_nodes <- apply(sub_all_nodes, 2, sort)
# save(sub_all_nodes, file = "results/sub_all_nodes.Rdata")
load("results/sub_all_nodes.Rdata")
# Table
pander(sub_all_nodes, caption = "Table showing the number of events within a node scored in descending order. The different columns show the SOM results based on subsets of the data. The first column 'all_all', shows the previous results on the full, unsubsetted, untrimmed, etc. data. Note that the full air data (i.e. temp, U and V) is the most similar to the un-subsetted results.")
```

As we see in the table above, separating the variables from one another has a large effect on the clustering of the data. Unexpectedly, the air data appear to produce results the most similar to the results generated by running the SOM analysis on the full data set. This suggests that the air data (UV more than temperature) are driving the SOM clusters, and not the sea data. My general perception of all of the tests and results thus far has been that it is the sea, and not the air, that is usually driving events. Which makes this result a bit trickier to deal with. The importance of air data on clustering the data must be acknowledged, but I also think that this provides a clear argument against clustering the data using all of the variables at once because we generally want to see what the effect the ocean temperature is having on the coastal MHWs. One reason why air temperature and winds may be having a stronger effect on the clustering is that they are much more even, allowing for easier clustering of the results. This issue may require further analysis but I will leave it as is for now.


## Do normal days cluster apart from events?
The idea here is to include the 366 daily synoptic climatology values in with the synoptic MHW values to see if they cluster differently. From previous SOM and K-means cluster analyses on these daily climatology values it was determined that 2 - 4 nodes/ clusters was optimal. Anything more than that was over fitting. I attribute this to the much more even nature of the climatological data. Therefore I hypothesised that if one were to cluster the daily clims with the event data they would be placed into different clusters. There are 95 events and 366 daily clims, so this should allow for a pattern to be seen if one does exist. Up until this point SOMs have been the primary tool of investigation into clustering, but for this last step I opt to use HCA to produce a dendrogram of the results. I do this because it provides a better visual index of the difference between the points. It also allows for a nice visual representation of the two different classes of data being compared (i.e. event data and daily clim data). Additionally, an MDS is run to allow for another dimension of spatial difference to be inferred.
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# Load the daily clim data and create a 0.5 degree mean
# load("~/AHW/data/all_daily.Rdata")
# all_daily_0.5 <- all_daily %>% 
  # mutate(x = round_any(x, 0.5)) %>% 
  # mutate(y = round_any(y, 0.5))
# all_daily_0.5 <- data.table(all_daily_0.5)
# all_daily_0.5 <- all_daily_0.5[, .(value = mean(value, na.rm = TRUE)),
                                   # by = .(x, y, variable, date)]
# all_daily_0.5$index <- paste0(all_daily_0.5$x,"_",all_daily_0.5$y,"_",all_daily_0.5$variable)
# save(all_daily_0.5, file = "results/all_daily_0.5.Rdata")
# load("results/all_daily_0.5.Rdata")

## With the daily data loaded, create anomaly values
# First create mean
# all_daily_mean_0.5 <- all_daily_0.5[, .(value = mean(value, na.rm = TRUE)),
                                   # by = .(x, y, variable)]
# Then order the two data frames the same
# all_daily_mean_0.5 <- all_daily_mean_0.5[order(all_daily_mean_0.5$variable, all_daily_mean_0.5$x, all_daily_mean_0.5$y),]
# all_daily_0.5 <- all_daily_0.5[order(all_daily_0.5$date, all_daily_0.5$variable, all_daily_0.5$x, all_daily_0.5$y),]
# Lastly subtract the mean for anomalies
# all_daily_anom_0.5 <- all_daily_0.5 %>% 
  # mutate(value = value-all_daily_mean_0.5$value)
# mean(all_daily_anom_0.5$value)
# save(all_daily_anom_0.5, file = "results/all_daily_anom_0.5.Rdata")
# load("results/all_daily_anom_0.5.Rdata") ## Daily Anomalies may be required to be loaded but are disabled for now... ##

# Test the anomaly output visually
# ggplot(data = all_daily_anom_0.5[all_daily_anom_0.5$event == "09-15" & all_daily_anom_0.5$variable == "BRAN/temp",], 
       # aes(x = x, y = y, fill = value)) +
  # geom_raster()
```
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# ## Merge the daily clim anomalies and the event anomalies in one long data frame before melting
# # Melt the event data
# all_anom_0.5_long <- melt(all_anom_0.5, id.vars = "event")
# all_anom_0.5_long$x <- as.numeric(sapply(strsplit(as.character(all_anom_0.5_long$variable), "_"), "[[", 1))
# all_anom_0.5_long$y <- as.numeric(sapply(strsplit(as.character(all_anom_0.5_long$variable), "_"), "[[", 2))
# all_anom_0.5_long$variable <- sapply(strsplit(as.character(all_anom_0.5_long$variable), "_"), "[[", 3)
# all_anom_0.5_long$variable <- sapply(strsplit(as.character(all_anom_0.5_long$variable), "-"), "[[", 1)
# all_anom_0.5_long$event <- sapply(strsplit(basename(as.character(all_anom_0.5_long$event)), ".Rdata"),  "[[", 1)
# all_anom_0.5_long$index <- paste0(all_anom_0.5_long$x,"_",all_anom_0.5_long$y,"_",all_anom_0.5_long$variable)
# # Change column name and order of daily anom clims
# colnames(all_anom_0.5_long)
# colnames(all_daily_anom_0.5)
# all_daily_anom_0.5 <- all_daily_anom_0.5[,c(4,3,5,1,2,6)]
# colnames(all_daily_anom_0.5) <- colnames(all_anom_0.5_long)
# all_daily_anom_0.5 <- data.frame(all_daily_anom_0.5)
# all_anom_0.5_long <- data.frame(all_anom_0.5_long)
# # Combine and cast
# all_event_daily_anom_0.5 <- rbind(all_anom_0.5_long, all_daily_anom_0.5)
# all_event_daily_anom_0.5$index_2 <- c(rep("event", nrow(all_anom_0.5_long)), rep("daily", nrow(all_daily_anom_0.5)))
# all_event_daily_anom_0.5 <- dcast(all_event_daily_anom_0.5, index_2+event~index, value.var = "value")
# # Add a season column
# all_event_daily_anom_0.5 <- data.frame(season = rep(NA, nrow(all_event_daily_anom_0.5)),
#                                        all_event_daily_anom_0.5)
# all_event_daily_anom_0.5 <- all_event_daily_anom_0.5 %>%
#   group_by(event) %>%
#   mutate(season = event_list$season[event_list$event == event[1]])
# all_event_daily_anom_0.5$season[all_event_daily_anom_0.5$event %in% summer] <- "summer"
# all_event_daily_anom_0.5$season[all_event_daily_anom_0.5$event %in% autumn] <- "autumn"
# all_event_daily_anom_0.5$season[all_event_daily_anom_0.5$event %in% winter] <- "winter"
# all_event_daily_anom_0.5$season[all_event_daily_anom_0.5$event %in% spring] <- "spring"

# # Save
# save(all_event_daily_anom_0.5, file = "results/all_event_daily_anom_0.5.Rdata")
load("results/all_event_daily_anom_0.5.Rdata") ## Daily Anomalies may be required to be loaded but are disabled for now... ##
```
```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Plot showing the decrease in WGSS as more clusters are used for the results of an HCA on the anomaly values for synoptic air-sea states during events and daily climatologies."}
# Check the stress of using differing clusters
# wss <- (nrow(all_event_daily_anom_0.5[,-c(1:3)])-1)*sum(apply(all_event_daily_anom_0.5[,-c(1:3)],2,var))
#   for (i in 2:15) wss[i] <- sum(kmeans(all_event_daily_anom_0.5[,-c(1:3)],
#                                        centers=i)$withinss)
# save(wss, file = "results/wss.Rdata")
load("results/wss.Rdata")
plot(1:15, wss, type = "b", xlab = "Number of Clusters",
     ylab = "Within groups sum of squares", main = "Daily Climatology and Event Anomaly Data")
```

Before running HCA and any other cluster or ordination techniques on these data we want to see how many clusters would be reasonable to use. The figure above shows that 4 to 6 is a good choice. With that known, we now run HCA, create a dendrogram and overlay some clusters.
```{r, warning=FALSE, message=FALSE, echo=FALSE}
# Run the HCA
library(vegan)
# all_event_daily_anom_0.5_hclust <- hclust(vegdist(decostand(all_event_daily_anom_0.5[,-c(1:3)],
#                                                             method = "standardize"),
#                                                   method = "euclidean"),
#                                           method = "ward.D2")
# save(all_event_daily_anom_0.5_hclust, file = "results/all_event_daily_anom_0.5_hclust.Rdata")
load("results/all_event_daily_anom_0.5_hclust.Rdata")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Dendrogram showing the results of an HCA on the anomaly values for synoptic air-sea states during events and daily climatologies. The daily clims and event data are shown with different colours. The dates or event names are included but are not legible."}
# Set the data types as factors
all_event_daily_anom_0.5$index_2 <- factor(all_event_daily_anom_0.5$index_2, levels = c("daily", "event"))
all_event_daily_anom_0.5$season <- factor(all_event_daily_anom_0.5$season, levels = c("summer", "autumn", "winter", "spring"))

# Vector of values for plotting
label_colour <-  c("royalblue3", "springgreen4") # This shows data type
label_font <- c("daily", "event")
label_shape <- c(15, 16, 17, 18) # This shows seasons

# Cluster colours
clust_colour <- c("orangered", "hotpink", "purple", "sienna")

# Index for labeling the pools
data_type_label <- as.numeric(all_event_daily_anom_0.5$index_2)
names(data_type_label) <- seq(1:length(all_event_daily_anom_0.5$index_2))

data_season_label <- as.numeric(all_event_daily_anom_0.5$season)
names(data_season_label) <- seq(1:length(all_event_daily_anom_0.5$season))

# Function to change label properties
point.lab <- function(n) {
    if (is.leaf(n)) {
        a <- attributes(n)
        # Label colour
        lab_col <- label_colour[data_type_label[which(names(data_type_label) == a$label)]]
        # Label text
        # lab_font <- label_font[data_label[which(names(data_label) == a$label)]]
        lab_font <- all_event_daily_anom_0.5$event[data_type_label[which(names(data_type_label) == a$label)]]
        # Label shape
        lab_shape <- label_shape[data_season_label[which(names(data_season_label) == a$label)]]
        # Index for shapes and labels
        attr(n, "nodePar") <- c(a$nodePar, list(lab.col = lab_col, col = lab_col,
                                                pch = 16, cex = 0.8, lab.cex = 0.3)) 
        # The line below changes the dendrogram labels from the pool number to the 'label_font' value
        # attr(n, "label") <- lab_font
        attr(n, "label") <- NA
    }
    n
}

# Change the dendrogram appearance
clust <- all_event_daily_anom_0.5_hclust
clust_d <- as.dendrogram(clust)
clust_full <- dendrapply(clust_d, point.lab)
grp <- cutree(clust, 4)

# Draw the plot
plot(clust_full, ylab = "Height")
rect.hclust(clust, k = 4, border = clust_colour)
legend("topright", legend = c("daily", "event"),
       col = label_colour, pch = 7, title = "Data Type")
# legend("right", legend = c("summer", "autumn", "winter", "spring"),
       # pch = label_shape, title = "Season")
```

The dendrogram from the HCA very clearly shows that the event data separate out from the daily clim data almost perfectly. Besides the overlayed clusters, one may also see that the final branch on which each event sits is much longer than the daily clims. This means that not only are the events clustered apart from the daily clim data, but also that the individual events are also much more dissimilar from any of the other data points than the daily clims. But let's not stop there. The dendrogram makes a very convincing case for the dissimilarity between event and daily clim data, but let's add another dimension by creating an ordiplot via MDS.

```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Ordiplot showing the results of an MDS on the anomaly values for synoptic air-sea states during events and daily climatologies. The daily clims and event data are shown with different colours. The dates or event names have not been included but are available. The clusters from the dendrogram are shown here with corresponding colours."}
# all_event_daily_anom_0.5_MDS <- metaMDS(vegdist(decostand(all_event_daily_anom_0.5[,-c(1:3)],
#                                                             method = "standardize"),
#                                                   method = "euclidean"), try = 100)
# save(all_event_daily_anom_0.5_MDS, file = "results/all_event_daily_anom_0.5_MDS.Rdata")
load("results/all_event_daily_anom_0.5_MDS.Rdata")

# The figure
anom_mds <- all_event_daily_anom_0.5_MDS
plot(anom_mds, type = "n")
points(anom_mds, display = "sites", cex = 0.7, 
       pch = label_shape[as.numeric(all_event_daily_anom_0.5$season)], 
       col = label_colour[as.numeric(all_event_daily_anom_0.5$index_2)])
# ordiellipse(anom_mds, grp, col = clust_colour[c(1,4,2,3)], kind = "ehull") # Mysteriously stopped working
ordihull(anom_mds, grp, col = clust_colour[c(1,4,2,3)], draw = "lines")
# text(anom_mds, display = "sites", cex = 0.5, col = "black", adj = c(0,1))
legend("topright", legend = c("daily", "event"),
       col = label_colour, pch = 7, title = "Data Type")
legend("right", legend = c("summer", "autumn", "winter", "spring"),
       pch = label_shape, title = "Season")
```

I find these results very exciting. I think this ordiplot shows very clearly that the synoptic air sea states during the 366 daily climatologies are different from almost all of the synoptic air-sea states during coastal MHWs. As one may see from the flat ellipse of blue squares (the daily clim points), the variance represented in the x axis is seasonality. Indeed, if the dates are included in the figure above they are in a contiguous state. With January 1st in the top left edge of the ellipse of blue squares and the dates then move clockwise. So May is roughly in the middle of the top of the ellipse and October in the middle on the bottom. The synoptic states during events appear to be controlled by the variance represented by the y axis. This must be some sort of variance that is aseasonal. Likely the anomalous characteristics of air and or sea that occur during the events. This will require further investigation but I think it will prove to be a very strong result. Even if it isn't central to the question of what are the air-sea states during extreme events, it certainly helps to show that whatever those states may be, they are different from the common air-sea states. Also worth noting is that the daily climatologies for summer and winter do not cluster at all with any of the events. They are almost all clustered with autumn, and a few with spring days.

```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Dotplot showing the clustering of the anomaly values for synoptic air-sea states during events and daily climatologies as shown in the dendrogram and ordiplot. The daily clims and event data are shown with different colours. The dates or event names are shown on the x axis but are illegible."}
ggplot(all_event_daily_anom_0.5, aes(x = event, y = grp, shape = season, colour = index_2)) + theme_dark() +
  geom_point() +
  labs(x = "date/ event", y = "cluster") +
  scale_color_discrete("data type") +
  # scale_y_continuous(labels = c("Summer", "Autumn", "Winter", "Spring")) +
  theme(axis.text.x = element_text(angle = 45, size = 3))
```

This dot plots shows the seasonality of the clustering in a chronological order. The colours of the dots show if they are daily climatologies or event data. The x axis shows the date or event name, but there are to many to read. The take away message from this is to see how the clustering very clearly progresses throughout the year in a very even fashion. With cluster 1 representing summer, 2 shows Autumn, 3 winter, and 4 is the spring days. Beyond that, we see that almost all of the event data is clustered in with the Autumn data. This means that conditions during autumn most closely resemble the air-sea state during an extreme event. This could be taken to mean that ecosystems are naturally at more risk during this time of year. Or, perhaps, due to the consistency of the seasonality, that species would be more prepared for these conditions during this time of year and therefore less susceptible. One would need to do more research to say. But that isn't the focus of this work anyway. When this figure is taken in conjunction with the MDS plot above we are able to say that the event data is not most like the autumn daily clims, but rather they are the least dissimilar to these data. Because they are very different from the daily clims.

I understand that this may not look as clear to the reader as it does to me, so please let me know in what ways I am failing to communicate the patterns I see in these data so I can better delve deeper into them in order to paint a clear picture for the publication.


# Hierarchical clustering
HCA differs from the other two techniques outlined below in that it does not cluster the data simultaneously, based on the least stress that can be found between data vectors. Rather it iteratively divides (or combines) data vectors as the algorithm moves down (or up) a classification tree. Always looking for the point at which clusters of data may be split (or combined). This method may benefit this research due to this one dimensional approach to clustering. It will display the patterns in a more linear way. This was already run above and it did indeed provide a strong argument for how normal days and MHW days cluster out from one another. Below we will look at HCA applied only to event days.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
# First calculate the HCA on the event data
# all_anom_0.5_hclust <- hclust(vegdist(decostand(all_anom_0.5[,-1], method = "standardize"),
#                                                   method = "euclidean"), method = "ward.D2")
# save(all_anom_0.5_hclust, file = "results/all_anom_0.5_hclust.Rdata")
load("results/all_anom_0.5_hclust.Rdata")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Dendrogram showing the results of an HCA on the anomaly values for synoptic air-sea states during events. The SOM nodes as calculated previously are shown in colour."}
# Set the data types as factors
all_anom_0.5$node <- factor(node_all_anom_pci_1r$node)

# Vector of values for plotting
label_colour <-  c("royalblue3", "springgreen4", "darkred", "gold", "lightcoral", 
                   "tomato", "maroon", "tan1", "slategray1") # This shows data type
label_font <- seq(1,9)
# label_shape <- c(15, 16, 17, 18) # This shows seasons

# Cluster colours
# clust_colour <- c("orangered", "hotpink", "purple", "sienna")

# Index for labeling the pools
data_type_label <- as.numeric(all_anom_0.5$node)
names(data_type_label) <- seq(1:length(all_anom_0.5$node))

# data_season_label <- as.numeric(all_event_daily_anom_0.5$season)
# names(data_season_label) <- seq(1:length(all_event_daily_anom_0.5$season))

# Function to change label properties
point.lab.a <- function(n) {
    if (is.leaf(n)) {
        a <- attributes(n)
        # Label colour
        lab_col <- label_colour[data_type_label[which(names(data_type_label) == a$label)]]
        # Label text
        # lab_font <- label_font[data_label[which(names(data_label) == a$label)]]
        # lab_font <- all_event_daily_anom_0.5$event[data_type_label[which(names(data_type_label) == a$label)]]
        # Label shape
        # lab_shape <- label_shape[data_season_label[which(names(data_season_label) == a$label)]]
        # Index for shapes and labels
        attr(n, "nodePar") <- c(a$nodePar, list(lab.col = "black", col = lab_col,
                                                pch = 16, cex = 0.8, lab.cex = 0.3)) 
        # The line below changes the dendrogram labels from the row number to the 'label_font' value
        # attr(n, "label") <- lab_font
        # attr(n, "label") <- NA
    }
    n
}

# Change the dendrogram appearance
clust <- all_anom_0.5_hclust
clust_d <- as.dendrogram(clust)
clust_full <- dendrapply(clust_d, point.lab.a)
grp <- cutree(clust, 9)

# Draw the plot
plot(clust_full, ylab = "Height")
rect.hclust(clust, k = 9, border = seq(1:9))
legend("topright", legend = seq(1:9),
       col = label_colour, pch = 7, title = "Node")
# legend("right", legend = c("summer", "autumn", "winter", "spring"),
       # pch = label_shape, title = "Season")
```


# K-means clustering
The simplest method of clustering, and for that reason still one of the best. This is a basic algorithm that takes all data vectors and positions them in a 2D space. It then picks K points and sees, given the best possible fit of all dimensions being used, which data vectors are closest to which of the K points. This process is then repeated n times until a best fit is found. The data vectors are classified into the cluster centroid to which they are closest. This method makes two critically flawed assumptions for our purposes. The first is that it assumes the data will be distributed around the centroids in a spherical manner, and the second is that K-means attempts to find equitable samples in each node. Also due to the width of the dataframe being used, there are no built in R functions that I have found that allow one to plot the results 'out of the box'. I therefore run an PCA on the data in order to extract the two largest principal components and plot these via an ordiplot with the K-means results overlayed.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Calculate K-means clustering
# all_anom_0.5$node <- NULL # Remove the node colun added for the HCA plotting to calculate the kmeans
# all_anom_0.5_kmeans <- kmeans(as.matrix(scale(all_anom_0.5[,-1])), centers = 9, iter.max = 100)
# save(all_anom_0.5_kmeans, file = "results/all_anom_0.5_kmeans.Rdata")
load("results/all_anom_0.5_kmeans.Rdata")

## Calculate PCA
# all_anom_0.5$node <- NULL
# all_anom_0.5_PCA <- prcomp(scale(all_anom_0.5[,-c(1)]))
# save(all_anom_0.5_PCA, file = "results/all_anom_0.5_PCA.Rdata")
load("results/all_anom_0.5_PCA.Rdata")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Ordiplot showing the results of K-means clustering on the event data. Axes determined via PCA. The colour of the points shows which K-means cluster the event has been placed in, whereas the colour of the poolygons shows in which cluster the events have been placed via HCA. Lastly, the shape of the point shows the results of the SOM clustering."}
# Create dataframe for plotting
kmeans_PCA <- data.frame(data.frame(all_anom_0.5_PCA$x[,1:2]), 
                         kmeans = as.factor(all_anom_0.5_kmeans$cluster), 
                         hca = as.factor(grp),
                         som = as.factor(node_all_anom_pci_1r$node))

# Get the convex hull of each unique point set
find_hull <- function(df) df[chull(df$PC1, df$PC2), ]
hulls <- ddply(kmeans_PCA, "som", find_hull)

# Plot the K-means clusters on the 2 principal components
ggplot(data = kmeans_PCA, aes(x = PC1, y = PC2)) +
  geom_point(aes(colour = kmeans, shape = hca)) +
  geom_polygon(data = hulls, aes(group = som, fill = som), alpha = 0.2) +
  scale_shape_manual(values = seq(6:14)) +
  theme(legend.position = "top")
```

Jikes! There is a lot going on in that figure. One could spend hours going over this. After several minutes of study it appears that the HCA and K-means methods are more similar to one another than the SOM. That being said, it seems that the PCA may agree best with the SOM results. And I'm not sure what to think of that. Either way, these are very interesting results and even though there is a big clomp in the center, this is to be expected and from the ordination work I've done in the past these results are much more clear than most things I've seen. Very encouraging. If I were to point out only one thing on this figure it would be that the clomp of 12 events that have always been clustered together, no matter what method is employed, stand out very clearly on the far right. Wonderful!

# SOMs
The originally proposed technique and perhaps, once this dust settles, the reigning champion. The SOM technique is apart from the previous two methods in that it accounts for the gradient that exists between the nodes it clusters the given data into. Meaning that the positions of the nodes in 2D space is relevant, unlike HCA and K-means. It is unnecessary to revisit the SOM clustering here as the majority of this document has already shown those results.


# MDS
Multi-dimensional scaling provides another possible layer of interpretation of these data, even though it is not in itself a clustering or ordination technique. By highlighting which pixels on the map belong to which meso-scale properties (e.g. Agulhas, Benguela, Agulhas retroflection) it is then possible to 'environmentally fit' the effect of these pixels, and therefore meso-scale features, on top of the ordiplots generated by MDS. This however presents a large undertaking and I think it begins to move outside of the scope of this proposed research project. It would however be an excellent next step in the process. The existing categorical variables of coast and season can however be readily fit to the data and this is shown below.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
## Calculate MDS
# all_anom_0.5$node <- NULL
# all_anom_0.5_MDS <- metaMDS(vegdist(decostand(all_anom_0.5[,-c(1)],
#                                               method = "standardize"), 
#                                     method = "euclidean"), try = 100)
# save(all_anom_0.5_MDS, file = "results/all_anom_0.5_MDS.Rdata")
load("results/all_anom_0.5_MDS.Rdata")
```
```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Ordiplot showing the MDS results on the event data. The two environmental variables of season and coast have been fit to the data. Vectors are not available as these are discrete variables."}
# Fit environmental variables
ord_fit <- envfit(all_anom_0.5_MDS ~ coast + season, data = event_list[,26:27])
# ord_fit
ord_fit_df <- as.data.frame(ord_fit$factors$centroids)
ord_fit_df$factors <- rownames(ord_fit_df)

# Create MDS dataframe
mds_df <- data.frame(all_anom_0.5_MDS$points)

# Plot the fits
ggplot(data = mds_df, aes(x = MDS1, y = MDS2)) +
  geom_point(colour = "salmon") +
  geom_text(data = ord_fit_df, aes(label = factors, x = NMDS1, y = NMDS2))

```

I intentionally omitted all of the other clustering results from this figure so as to allow for the effect of the environmental variables to stand out on their own. Notably, they do not. There is very little environmental effect from these two categories. The east coast events stand out a bit from the rest, which is worth mentioning. This is not surprising, and only serves to support the hypothesis that the east coast, controlled by the (relatively) consistent Agulhas current is different from the south and west coasts. If we look at the significance of the fit of these variables we see that the fit of the coastal variables is significant at _p_ = `r ord_fit$factors$pvals[1]` but that season is not at _p_ = `r ord_fit$factors$pvals[2]`.

# ANOSIM
Before we look at all of the results laid out next to each other, let's have a peak at the analysis of similarity for the clusterings of the three methods.

```{r, warning=FALSE, message=FALSE, echo=FALSE}
# Remove node column again
all_anom_0.5$node <- NULL

# HCA
hca_anosim <- anosim(vegdist(decostand(all_anom_0.5[,-1], method = "standardize"),
                                                  method = "euclidean"), grp)
# hca_anosim

# K-means
kmeans_anosim <- anosim(as.matrix(scale(all_anom_0.5[,-1])), all_anom_0.5_kmeans$cluster)
# kmeans_anosim

# SOM
som_anosim <- anosim(as.matrix(scale(all_anom_0.5[,-1])), node_all_anom_pci_1r$node)
# som_anosim
```

All three clustering techniques produce significantly different clusters when 9 are used at _p_ = 0.001. This is good as it means I don't have to redo everything to satisfy this requirement... From a non-lazy point of view this is also good because it shows that these techniques are effectively finding differences in the data and partitioning them accordingly. Rather surprisingly (or perhaps not) HCA is by far the winner with the largest R (this represents cluster dissimilarity, not a correlation value, confusing yes) = `r round(hca_anosim$statistic, 3)`. K-means is in second at R = `r round(kmeans_anosim$statistic, 3)` with SOM taking up third at R = `r round(som_anosim$statistic, 3)`. This is perhaps not surprising in that these results represent the gradient in selectivity that these three techniques employ when clustering/ ordinating data. 

# Comparison
Now that the clustering/ ordination of all of the different techniques has been run, we may plot all of them side by side. There are of course a near limitless number of ways in which this may be done, but I've chosen to use lolliplots. Because I like them. I also think they do a good job of conveying the many dimensions of the data well.

```{r, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Lolliplots for all three methods shown together in three panels. Each facet shows the events clustered into each grouping."}
# Add other cluster results
node_all_anom_2$hca <- grp
node_all_anom_2$kmeans <- all_anom_0.5_kmeans$cluster

# The SOM results
lolli_som <- ggplot(data = node_all_anom_2, aes(x = date_start, y = int_cum)) +
  geom_lolli() +
  facet_wrap(~node) +
  labs(x = "date", y = "cummulative intensity (Cxdays)") +
  ggtitle("SOM nodes") + 
 theme(strip.background = element_blank(),
       strip.text.x = element_blank())

# The K-means results
lolli_kmeans <- ggplot(data = node_all_anom_2, aes(x = date_start, y = int_cum)) +
  geom_lolli() +
  facet_wrap(~kmeans) +
  labs(x = "date", y = "cummulative intensity (Cxdays)") +
  ggtitle("K-means clusters") + 
 theme(strip.background = element_blank(),
       strip.text.x = element_blank())

# The HCA results
lolli_hca <- ggplot(data = node_all_anom_2, aes(x = date_start, y = int_cum)) +
  geom_lolli() +
  facet_wrap(~hca) +
  labs(x = "date", y = "cummulative intensity (Cxdays)") +
  ggtitle("HCA") + 
 theme(strip.background = element_blank(),
       strip.text.x = element_blank())

# Combine
library(gridExtra)
grid.arrange(lolli_som, lolli_kmeans, lolli_hca, widths = c(12,12,12))
```

This will take some time to unpack. It is also still necessary to visualise these clusters in order to see more clearly what it is that the air-sea state is up to that had the different methods setting their minds on how to cluster the events as they have. But for now these lolliplots allow for a cursory examination of the clustering in a different manner than the figure preceding this one. It is important to note that while the orientation of the nodes in the SOM results on the top panel are relevant, the cluster/ ordination layout of the 9 facets in the HCA and K-means results are not. This makes it a bit difficult to compare the results as it is not a direct task. Node/ cluster labels have been omitted for a cleaner visualisation.

# References