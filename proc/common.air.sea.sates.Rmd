---
title: "Common Air-Sea States"
output: html_notebook
---

# Rationale
In order to better understand the results of either hierarchical clustering or SOMs on the air-sea states during MHWs, it is necessary to also create cluster analyses on the 'normal' air-sea states as well. There are many possible ways of doing this however, the datasets (BRAN particularly) are massive so some method of dimension reduction is required. The daily climatologies (same as the seasonal climatology values from the MHW smoothing methodology) for all temperature, u and v pixels for both BRAN and ERA have already been calculated so this is used in lieu of running a cluster analysis on every day of air-sea data available across both datasets. The same methodology is applied to anomaly data generated by subtracting the overall mean air-sea state from the daily climatologies. The reason this is done for both the normal and anomaly data is that, I believe, they give two different impressions. This is particularly true for the u and v values.

```{r, echo=FALSE, message=FALSE}
library(plyr)
library(dplyr)
library(reshape2)
library(data.table)
library(ggplot2)
library(grid)
library(viridis)
library(vegan)
```

# Methods
## Loading
The first step is to load these rather large data frames into virtual memory and combine them into one long massive data frame.

```{r, echo=FALSE}
# # BRAN
# load("~/AHW/data/BRAN/BRAN_temp_daily.Rdata")
# load("~/AHW/data/BRAN/BRAN_u_daily.Rdata")
# load("~/AHW/data/BRAN/BRAN_v_daily.Rdata")
# # ERA
# load("~/AHW/data/ERA/ERA_all_daily.Rdata")
# 
# # Create common column naming convention
# colnames(BRAN_temp_daily)[4] <- "value"
# BRAN_temp_daily$variable <- "BRAN/temp"
# colnames(BRAN_u_daily)[4] <- "value"
# BRAN_u_daily$variable <- "BRAN/u"
# colnames(BRAN_v_daily)[4] <- "value"
# BRAN_v_daily$variable <- "BRAN/v"
# ERA_all_daily <- melt(ERA_all_daily, id.vars = c("x","y","date"))
# ERA_all_daily$variable <- paste0("ERA/",ERA_all_daily$variable)
# 
# # Combine
# all_daily <- rbind(BRAN_temp_daily, BRAN_u_daily, BRAN_v_daily, ERA_all_daily)
# all_daily$x <- round(all_daily$x,2) # Have to use second decimal place as first decimal rounding creates possible duplicate entries
# all_daily$y <- round(all_daily$y,2)
# all_daily$index <- paste0(all_daily$x,"_",all_daily$y,"_",all_daily$variable)
# save(all_daily, file = "~/AHW/data/all_daily.Rdata")
# 
# # Free up some virtual memmory
# rm(list = c("BRAN_temp_daily", "BRAN_u_daily", "BRAN_v_daily", "ERA_all_daily"))
```
```{r}
# The code that creates this file is RAM and time intensive
# Therefore the assembled file has been saved and is simply loaded here
load("~/AHW/data/all_daily.Rdata")
```

## Pixel Reduction
Before the data are transposed, it is necessary to reduce the resolution in the BRAN data so that the sea variables are not over-represented against the ERA data. Further pixel reduction is also performed here in order to investigate the effects pixel resolution may be having on the clustering model capabilities. Meaning, if the resolution is made more course, does this allow for better model fitting. And do these better fits allow for more meaningful results.

```{r}
# 0.5 degree resolution
all_0.5 <- all_daily %>% 
  mutate(x = round_any(x, 0.5)) %>% 
  mutate(y = round_any(y, 0.5))
all_0.5 <- data.table(all_0.5)
all_0.5 <- all_0.5[, .(value = mean(value, na.rm = TRUE)),
                                   by = .(x, y, variable, date)]
all_0.5$index <- paste0(all_0.5$x,"_",all_0.5$y,"_",all_0.5$variable)

# 1.0 degree resolution
all_1.0 <- all_0.5 %>% 
  mutate(x = round_any(x, 1.0)) %>% 
  mutate(y = round_any(y, 1.0))
all_1.0 <- data.table(all_1.0)
all_1.0 <- all_1.0[, .(value = mean(value, na.rm = TRUE)),
                                   by = .(x, y, variable, date)]
all_1.0$index <- paste0(all_1.0$x,"_",all_1.0$y,"_",all_1.0$variable)

# 2.0 degree resolution... for interests sake
all_2.0 <- all_1.0 %>% 
  mutate(x = round_any(x, 2.0)) %>% 
  mutate(y = round_any(y, 2.0))
all_2.0 <- data.table(all_2.0)
all_2.0 <- all_2.0[, .(value = mean(value, na.rm = TRUE)),
                                   by = .(x, y, variable, date)]
all_2.0$index <- paste0(all_2.0$x,"_",all_2.0$y,"_",all_2.0$variable)
```


## Transposing
Once that is done it is necessary to transpose the data so that each daily air-sea climatology can be given to hierarchical clustering in order to be grouped.

```{r}
# Cast by day to create wide data frames with 366 rows
all_daily_wide <- dcast(all_daily, date~index, value.var = "value")
rownames(all_daily_wide) <- all_daily_wide$date
all_daily_wide$date <- NULL
rm(all_daily)

all_0.5_wide <- dcast(all_0.5, date~index, value.var = "value")
rownames(all_0.5_wide) <- all_0.5_wide$date
all_0.5_wide$date <- NULL
rm(all_0.5)

all_1.0_wide <- dcast(all_1.0, date~index, value.var = "value")
rownames(all_1.0_wide) <- all_1.0_wide$date
all_1.0_wide$date <- NULL
rm(all_1.0)

all_2.0_wide <- dcast(all_2.0, date~index, value.var = "value")
rownames(all_2.0_wide) <- all_2.0_wide$date
all_2.0_wide$date <- NULL
rm(all_2.0)
```

## Clustering
After transposing the data they may now be clustered via any number of methods. Here we use hierarchical clustering as it is the most straightforward.

```{r}
# A function for running standardization and euclidean distance at once
all.vegdist <- function(df){
  deco <- decostand(df, method = "standardize") # Standardize all values for similarity
  dis <- vegdist(deco, method = "euclidean") # Distance matrix for ordinations
  return(dis)
}

# Run hierarchical clustering
all_daily_clust <- hclust(all.vegdist(all_daily_wide), method = "ward.D2")
all_0.5_clust <- hclust(all.vegdist(all_0.5_wide), method = "ward.D2")
all_1.0_clust <- hclust(all.vegdist(all_1.0_wide), method = "ward.D2")
all_2.0_clust <- hclust(all.vegdist(all_2.0_wide), method = "ward.D2")
```

Have a quick peak at how increasing clusters reduces stress of the fit.
```{r}
# Full resolution
wss <- (nrow(all_daily_wide)-1)*sum(apply(all_daily_wide,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(all_daily_wide,
                                       centers=i)$withinss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters",
     ylab = "Within groups sum of squares", main = "Daily Full Resolution Data")
# 0.5 degree resolution
wss <- (nrow(all_0.5_wide)-1)*sum(apply(all_0.5_wide,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(all_0.5_wide,
                                       centers=i)$withinss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters",
     ylab = "Within groups sum of squares", main = "Daily 0.5 Resolution Data")
# 1.0 degree resolution
wss <- (nrow(all_1.0_wide)-1)*sum(apply(all_1.0_wide,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(all_1.0_wide,
                                       centers=i)$withinss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters",
     ylab = "Within groups sum of squares", main = "Daily 1.0 Resolution Data")
# 2.0 degree resolution
wss <- (nrow(all_2.0_wide)-1)*sum(apply(all_2.0_wide,2,var))
  for (i in 2:15) wss[i] <- sum(kmeans(all_2.0_wide,
                                       centers=i)$withinss)
plot(1:15, wss, type = "b", xlab = "Number of Clusters",
     ylab = "Within groups sum of squares", main = "Daily 2.0 Resolution Data")
```

As one may see in the hierarchical clustering of the events, there are very clearly two different clusters, regardless of the resolution to which the pixels are rounded. Note that the y axis on these dendrograms reduces drastically as coarser resolutions are used. This implies that the data become more similar when they become coarser. As expected.
```{r}
# Full resolution
plot(all_daily_clust, hang = -0.05, cex = 0.4, main = "Daily Full Resolution Data")
rect.hclust(all_daily_clust, k = 6, border = "red")
# 0.5 degree resolution
plot(all_0.5_clust, hang = -0.05, cex = 0.4, main = "Daily 0.5 Resolution Data")
rect.hclust(all_0.5_clust, k = 6, border = "red")
# 1.0 degree resolution
plot(all_1.0_clust, hang = -0.05, cex = 0.4, main = "Daily 1.0 Resolution Data")
rect.hclust(all_1.0_clust, k = 6, border = "red")
# 2.0 degree resolution
plot(all_2.0_clust, hang = -0.05, cex = 0.4, main = "Daily 2.0 Resolution Data")
rect.hclust(all_2.0_clust, k = 6, border = "red")
```

The number of clusters to round the data into is then chosen manually. If it is decided to go this route for the paper, rather than SOMs, I will properly investigate the appropriate clustering techniques to use based on a literature review. For now I am producing simple results for inspection.

```{r}
all_daily_groups <- cutree(all_daily_clust, k = 6)
all_0.5_groups <- cutree(all_0.5_clust, k = 6)
all_1.0_groups <- cutree(all_1.0_clust, k = 6)
all_2.0_groups <- cutree(all_2.0_clust, k = 6)
```

The clusters are then applied to the large data frames in order to create several mean air-sea states at the different resolutions.
```{r}
# Function for appropriate melting
group.melt <- function(wide, clusters){
  wide$cluster <- clusters
  long <- melt(wide, id.vars = "cluster")
  long <- as.data.table(long)
  long <- long[, .(value = mean(value, na.rm = TRUE)),
                                   by = .(cluster, variable)]
  return(long)
}

all_daily_long <- group.melt(all_daily_wide, all_daily_groups)
all_0.5_long <- group.melt(all_0.5_wide, all_0.5_groups)
all_1.0_long <- group.melt(all_1.0_wide, all_1.0_groups)
all_2.0_long <- group.melt(all_2.0_wide, all_2.0_groups)
```

## Visualisation
With the mean air-sea states calculated, the results may now be visualised.
```{r}
# But first we need to clean up the data frames
clean.long <- function(long){
  long$x <- as.numeric(sapply(strsplit(as.character(long$variable), "_"), "[[", 1))
  long$y <- as.numeric(sapply(strsplit(as.character(long$variable), "_"), "[[", 2))
  long$var <- sapply(strsplit(as.character(long$variable), "_"), "[[", 3)
  long$variable <- NULL
  return(long)
}

all_daily_long <- clean.long(all_daily_long)
all_0.5_long <- clean.long(all_0.5_long)
all_1.0_long <- clean.long(all_1.0_long)
all_2.0_long <- clean.long(all_2.0_long)
```

```{r, echo=FALSE}
# Load SA map data
load("~/AHW/graph/southern_africa_coast.RData") # Lowres
names(southern_africa_coast)[1] <- "lon"

# The lon/ lat ranges
wlon <- 10
elon <- 40
nlat <- -25
slat <- -40

sa_lons <- c(10, 40); sa_lats <- c(-40, -25)

# The plotting function
# NB: This function requires input generated from 'all.panels()'
cluster.panels <- function(data_temp, data_uv, plot_title, legend_title, vector_label, viridis_col){
  cp <- ggplot(data = data_temp, aes(x = x, y = y)) +
    geom_raster(aes(fill = value)) +
    geom_segment(data = data_uv, aes(x = x, y = y, xend = x + u, yend = y + v),
                 arrow = arrow(angle = 15, length = unit(0.02, "inches"), type = "closed"), alpha = 0.2) +
    geom_polygon(data = southern_africa_coast, aes(x = lon, y = lat, group = group),
                 fill = NA, colour = "black", size = 0.5, show.legend = FALSE) +
    scale_x_continuous(limits = sa_lons, expand = c(0, 0), breaks = seq(15, 35, 5),
                       labels = scales::unit_format("°E", sep = "")) +
    scale_y_continuous(limits = sa_lats, expand = c(0, 0), breaks = seq(-35, -30, 5),
                       labels = c("35°S", "30°S")) +
    coord_fixed(xlim = c(10.5, 39.5), ylim = c(-39.5, -25.5), expand = F) +
    xlab("") + ylab("") + ggtitle(plot_title) +
    scale_fill_viridis(legend_title, option = viridis_col) +
    facet_wrap(~cluster, nrow = ceiling((length(unique(data_temp$cluster))/3))) +
    theme(plot.title = element_text(hjust = 0.5, size = 12),
          panel.background = element_rect(fill = "grey70"),
          panel.border = element_rect(fill = NA, colour = "black", size = 1),
          panel.grid.major = element_line(colour = "grey70"),
          panel.grid.minor = element_line(colour = "grey70"),
          legend.position = "right",
          legend.direction = "vertical",
          strip.text = element_text(size = 12),
          strip.background = element_rect(fill = NA),
          legend.key.height = unit(1.1, "cm"),
          axis.text = element_text(size = 12),
          legend.text = element_text(size = 12),
          legend.title = element_text(size = 12))
  # cp
  return(cp)
}

# The function that puts it all together
# data_res <- res_all_norm # tester...
all.panels <- function(data_res, resolution, reduce_BRAN = FALSE, reduce_ERA = FALSE){
  data_res$var <- as.factor(data_res$var)
  ## Separate BRAN from ERA and temp from uv
  # BRAN
  res_BRAN_temp <- data_res[data_res$var == levels(data_res$var)[1],]
  res_BRAN_uv <- data_res[data_res$var %in% levels(data_res$var)[2:3],]
  res_BRAN_uv <- dcast(res_BRAN_uv, x+y+cluster~var)
  colnames(res_BRAN_uv)[4:5] <- c("u", "v")
  if(reduce_BRAN){
    lon_sub <- seq(10, 40, by = 0.5)
    lat_sub <- seq(-40, -15, by = 0.5)
    res_BRAN_uv <- res_BRAN_uv[(res_BRAN_uv$x %in% lon_sub & res_BRAN_uv$y %in% lat_sub),]
  }
  
  # ERA
  res_ERA_temp <- data_res[data_res$var == levels(data_res$var)[4],]
  res_ERA_uv <- data_res[data_res$var %in% levels(data_res$var)[5:6],]
  res_ERA_uv <- dcast(res_ERA_uv, x+y+cluster~var)
  colnames(res_ERA_uv)[4:5] <- c("u", "v")
  res_ERA_uv$u <- res_ERA_uv$u/2
  res_ERA_uv$v <- res_ERA_uv$v/2
  if(reduce_ERA){
    lon_sub <- seq(10, 40, by = 1)
    lat_sub <- seq(-40, -15, by = 1)
    res_ERA_uv <- res_ERA_uv[(res_ERA_uv$x %in% lon_sub & res_ERA_uv$y %in% lat_sub),]
  }

  
  # Determine titles to use
  if(sum(res_BRAN_temp$value) >= 500){
    plot_title_BRAN = "SST + Current"
    plot_title_ERA = "Air Temp + Wind"
    legend_title = "Temp.\n(°C)"
    data_type = "norm"
  } 
  if(sum(res_BRAN_temp$value) < 500){
    plot_title_BRAN = "SST Anomaly + Current Anomaly"
    plot_title_ERA = "Air Temp Anomaly + Wind Anomaly"
    legend_title = "Anom.\n(°C)"
    data_type = "anom"
  } 
  
  ## The  panel figures
  # BRAN
  panels_BRAN <- cluster.panels(data_temp = res_BRAN_temp, data_uv = res_BRAN_uv,
                             plot_title = plot_title_BRAN, legend_title = legend_title, vector_label = "1.0 m/s\n", viridis_col = "D")
  # panels_BRAN
  # ERA
  panels_ERA <- cluster.panels(data_temp = res_ERA_temp, data_uv = res_ERA_uv,
                            plot_title = plot_title_ERA, legend_title = legend_title, vector_label = "4.0 m/s\n", viridis_col = "A")
  # panels_ERA
  
  # The figure
    # Generate file name
  file_name <- paste0("~/AHW/graph/cluster/daily_",resolution,"_",data_type,"_",length(unique(res_BRAN_temp$cluster)),".pdf")
  # The figure
  pdf(file_name, width = 10, height = 12, pointsize = 10) # Set PDF dimensions
  grid.newpage()
  pushViewport(viewport(layout = grid.layout(2,1)))
  vplayout <- function(x, y) viewport(layout.pos.row = x, layout.pos.col = y)
  print(panels_BRAN, vp = vplayout(1,1))
  print(panels_ERA, vp = vplayout(2,1))
  dev.off()
  a <- 1 # This simply distracts Rmarkdown from producing any messages
}
```

The figures are saved independent of this report as they are shrunk too much here.
```{r}
all.panels(all_daily_long, "full", TRUE, TRUE)
all.panels(all_0.5_long, "0.5", reduce_ERA = TRUE)
all.panels(all_1.0_long, "1.0")
all.panels(all_2.0_long, "2.0")
```

